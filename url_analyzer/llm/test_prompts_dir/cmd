cd /Users/danshiebler/workspace/personal/mlx-examples/llama
deactivate
source env/bin/activate



export PROMPT_PATH=/Users/danshiebler/workspace/personal/pentesting/kali/llm_utils/test_prompts_dir/prompt_2; \
python llama.py  \
   --model Llama-2-7b-chat-mlx/Llama-2-7b-chat.npz  \
   --prompt_path $PROMPT_PATH \
  --tokenizer  Llama-2-7b-chat-mlx/tokenizer.model